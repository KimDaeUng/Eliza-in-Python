{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliza in Python (2)\n",
    "\n",
    "본 내용은 The 11th International Conference on Computational Semantics(IWCS 2015)의 부대 행사인 Computational Semantics Hackathon의 자료 중 Dialogue system 파트를 번역한 자료입니다([출처](https://github.com/iwcs15-hack/dialog_system)).\n",
    "  \n",
    "Part-Of-Speech tagging preprocessor를 사용하여 Eliza를 보다 개선한 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기선 POS(Part Of Speech) tagger를 불러와 활용한다. POS tagger는 입력된 단어들을 요소로 갖는 리스트를 입력받아(정확히는 입력된 문장을 tokenizing한 token들을 입력 받아) 이를 분석해 문장 내에서의 각 token의 문법적 역할(품사)을 출력한다.\n",
    "\n",
    "아래 예제에서는 NLTK를 사용하여 POS tagger를 만든다. NLTK는 몇 가지 tagger를 내장하고 있긴하지만, Eliza에 적합한 것들은 없어서 직접 만들어볼 것이다.\n",
    "\n",
    "여기선 [the Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus)라 하는 POS tagging이 비교적 잘 되어있는 데이터셋을 이용해 POS tagger를 훈련시킬 것이다. tag의 각 항목들은 [여기](http://www.comp.leeds.ac.uk/ccalas/tagsets/brown.html)에서 확인할 수 있다. 이 tag set에서 실질적으로 유용한 점은 아래 두 가지이다.\n",
    "  \n",
    "- 첫째, 이것은 주격 대명사(subject pronoun)와 목적격 대명사(object pronoun)를 구분한다(주격 명사를 `PPSS`, 목적격 명사를 `PPO` tag로 구별한다). 따라서 단어 `you`가 함수 `translate`로 변환될 때 주격인 `I`로 변환되어야할지 목적격인 `me`로 변환되어야할지를 결정할 수 있다.\n",
    "\n",
    "- 둘쨰, 이것은 주어가 일반명사(common nouns)와 고유명사(proper nouns)를 구분한다(일반명사이면 `NN`, 고유명사이면 `NP` tag로 구별한다). 따라서 문장의 첫번째로 오는 대문자 단어를 챗봇의 답변 문장의 중간에 포함시킬 때, 대문자를 유지할 것인지를 결정할 수 있다.\n",
    "\n",
    "아래 코드는 tagger를 빌드하고 pickle로 저장하는 코드이다.\n",
    "```python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/dukim/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the brown corpus\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training & saving the POS tagger\n",
    "unigram_tagger = nltk.UnigramTagger(nltk.corpus.brown.tagged_sents())\n",
    "brill_tagger_trainer = nltk.tag.brill_trainer.BrillTaggerTrainer(unigram_tagger, nltk.tag.brill.brill24())\n",
    "tagger = brill_tagger_trainer.train(nltk.corpus.brown.tagged_sents(), max_rules=1000)\n",
    "outfile = open(\"bbt.pkl\", \"wb\")\n",
    "dump(tagger, outfile, -1)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보다시피 대부분의 작업이 NLTK로 이뤄진다. 하지만 NLTK 내부에서 어떤 일이 일어나고 있는지 알 필요가 있다. 여기서 우리는 [Brill Tagging](https://en.wikipedia.org/wiki/Brill_tagger)이라 불리는 알고리즘을 사용한다. 이에 대해 NLTK 공식 문서에서는 [Chapter 5의 Section 6](http://www.nltk.org/book/ch05.html)에서 설명하고 있다. 이 알고리즘은 단순한 tagger인 `Unigram Tagger`를 개선하여 만든 것으로, `Unigram Tagger`는 맥락은 무시한채, 각 단어가 문장에서 가장 많이 맡게되는 품사로 태깅한다.  \n",
    "`BrillTaggerTrainer`는 기존 `Unigram Tagger`에서 발생하는 실수들을 수정하는 규칙들을 발견한다. 이러한 규칙들은 다양한 feature를 사용하는데, 예를 들어 주변 단어와, 주변 단어의 품사 등을 활용한다. 위 코드를 실행하면 이 training data를 사용하여 가능한 규칙들을 탐색하고, unigram tagger에서 제대로 처리하지 못 하는 것들을 처리할 수 있는 규칙들을 찾을 것이다. 그러나 POS tagger를 학습시키는데 시간이 오래 걸리기 때문에, 나중을 위하여 pickle 파일로 저장한다. 저장된 tagger는 NLTK에 대한 의존성이 없기 때문에 나중엔 NLTK를 불러오지 않고도 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "infile = open(\"bbt.pkl\", \"rb\")\n",
    "tagger = load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle을 이용해 `tagger`를 불러온 다음에는, 사용자의 발화(utterance)를 tokeninzing 하여 리스트 `L`로 만들고, 함수 `tagger.tag(L)`를 실행한다. 실행결과, (단어, 품사) 쌍을 원소로 갖는 리스트를 얻는다.  \n",
    "아래는 간단한 tokenizer 함수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text) :\n",
    "    return [tok for tok in re.split(r\"\"\"([,.;:?\"]?)   # optionally, common punctuation \n",
    "                                         (['\"]*)      # optionally, closing quotation marks\n",
    "                                         (?:\\s|\\A|\\Z) # necessarily: space or start or end\n",
    "                                         ([\"`']*)     # snarf opening quotes on the next word\n",
    "                                         \"\"\", \n",
    "                                    text, \n",
    "                                    flags=re.VERBOSE)\n",
    "            if tok != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 기존 `translate` 함수가 처리하지 못했던 케이스를 개선할 수 있다. 기존의 `reflection_of` dictionary는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "untagged_reflection_of = {\n",
    "    \"am\"    : \"are\",\n",
    "    \"i\"     : \"you\",\n",
    "    \"i'd\"   : \"you would\",\n",
    "    \"i've\"  : \"you have\",\n",
    "    \"i'll\"  : \"you will\",\n",
    "    \"i'm\"   : \"you are\",\n",
    "    \"my\"    : \"your\",\n",
    "    \"me\"    : \"you\",\n",
    "    \"you've\": \"I have\",\n",
    "    \"you'll\": \"I will\",\n",
    "    \"you're\": \"I am\",\n",
    "    \"your\"  : \"my\",\n",
    "    \"yours\" : \"mine\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 버전은 주격 대명사와 목적격 대명사를 잘 구분하지 못했지만, 이 버전은 앞에서 학습한 tagger를 이용하여 구분할 수 있다. 각 token을 tagging해 얻은 튜플을 통해 바꿀 단어를 대응시키는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_reflection_of = {\n",
    "    (\"you\", \"PPSS\") : \"I\",\n",
    "    (\"you\", \"PPO\") : \"me\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 개별 token을 translate 하는 코드이다. capitalization을 처리하기 위해서 `NP` tag를 이용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_token(x):\n",
    "    word, tag = x\n",
    "    wl = word.lower()\n",
    "    if (wl, tag) in tagged_reflection_of:\n",
    "        return (tagged_reflection_of[wl, tag], tag)\n",
    "    if wl in untagged_reflection_of:\n",
    "        return (untagged_reflection_of[wl], tag)\n",
    "    if tag.find(\"NP\") < 0:\n",
    "        return (wl, tag)\n",
    "    return (word, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한편, `are`나 `were`와 같은 동사를 처리하는 것은 좀 더 까다롭다. tagger가 2인칭 주어인 `you`나 3인칭 복수 `they`를 나타내지는 않기 때문이다. 그러나, 영어에서는 주어가 대개 동사에 꽤 가까이에 위치하고, `you`와 같은 단어가 이어지는 단어에 따라 변형되는 일이 없다. 따라서 동사에 가장 가까운 명사구를 찾아서 동사의 주어가 우리가 목표로 삼고자 하는 대명사 중 하나인지 유추할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_tags = [\"PPS\",  # he, she, it\n",
    "                \"PPSS\", # you, we, they\n",
    "                \"PN\",   # everyone, someone\n",
    "                \"NN\",   # dog, cat\n",
    "                \"NNS\",  # dogs, cats\n",
    "                \"NP\",   # Fred, Jane\n",
    "                \"NPS\"   # Republicans, Democrats\n",
    "                ]\n",
    "\n",
    "def swap_ambiguous_verb(tagged_words, tagged_verb_form, target_subject_pronoun, replacement) :\n",
    "    for i, (w, t) in enumerate(tagged_words) :\n",
    "        if (w, t) == tagged_verb_form :\n",
    "            j = i - 1\n",
    "            # look earlier for the subject\n",
    "            while j >= 0 and tagged_words[j][1] not in subject_tags :\n",
    "                j = j - 1\n",
    "            # if subject is the target, swap verb forms\n",
    "            if j >= 0 and tagged_words[j][0].lower() == target_subject_pronoun :\n",
    "                tagged_words[i] = replacement\n",
    "            # didn't find a subject before the verb, so probably a question \n",
    "            if j < 0 :\n",
    "                j = i + 1\n",
    "                while j < len(tagged_words) and tagged_words[j][1] not in subject_tags :\n",
    "                    j = j + 1\n",
    "                # if subject is the target, swap verb forms\n",
    "                if j < len(tagged_words) and tagged_words[j][0].lower() == target_subject_pronoun :\n",
    "                    tagged_words[i] = replacement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 버전에서 동사의 주어를 잘못 처리하는 경우는 \"are\", \"am\", \"were\" 그리고 \"was\"의 네 가지 경우이다. 잘못 처리된 동사를 고치는 함수는 다음과 같다. 처리하기 전에 구두점을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_specials(tagged_words) :\n",
    "    # don't keep punctuation at the end\n",
    "    while tagged_words[-1][1] == '.' :\n",
    "        tagged_words.pop()\n",
    "    # replace verb \"be\" to agree with swapped subjects\n",
    "    swap_ambiguous_verb(tagged_words, (\"are\", \"BER\"), \"i\", (\"am\", \"BEM\"))\n",
    "    swap_ambiguous_verb(tagged_words, (\"am\", \"BEM\"), \"you\", (\"are\", \"BER\"))\n",
    "    swap_ambiguous_verb(tagged_words, (\"were\", \"BED\"), \"i\", (\"was\", \"BEDZ\"))\n",
    "    swap_ambiguous_verb(tagged_words, (\"was\", \"BEDZ\"), \"you\", (\"were\", \"BED\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 과정을 하나로 합쳐보자. 먼저 문장을 token으로 변환하고, 각 token에 POS tagging을 실시한다. 그 다음 tag를 이용해 translate를 수행하고, 잘못 변환된 동사를 처리한 뒤, 결과를 출력한다.  \n",
    "여기서 사용된 tagger는 다양한 유형의 구두점을 잘 잡아내기 때문에, 출력될 문장에서 어디에 공백을 넣을지 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_punc = ['.', ',', \"''\"]\n",
    "def translate(this):\n",
    "    tokens = tokenize(this)\n",
    "    tagged_tokens = tagger.tag(tokens)\n",
    "    translation = [translate_token(tt) for tt in tagged_tokens]\n",
    "    handle_specials(translation)\n",
    "    if len(translation) > 0 :\n",
    "        with_spaces = [translation[0][0]]\n",
    "        for i in range(1, len(translation)) :\n",
    "            if translation[i-1][1] != '``' and translation[i][1] not in close_punc :\n",
    "                with_spaces.append(' ')\n",
    "            with_spaces.append(translation[i][0])           \n",
    "    return ''.join(with_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규표현식을 이용한 규칙은 이전과 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [(re.compile(x[0]), x[1]) for x in [\n",
    "   ['How are you?',\n",
    "      [ \"I'm fine, thank you.\"]],\n",
    "    [\"I need (.*)\",\n",
    "    [   \"Why do you need %1?\",\n",
    "        \"Would it really help you to get %1?\",\n",
    "        \"Are you sure you need %1?\"]],\n",
    "    [\"Why don't you (.*)\",\n",
    "    [   \"Do you really think I don't %1?\",\n",
    "        \"Perhaps eventually I will %1.\",\n",
    "        \"Do you really want me to %1?\"]],\n",
    "    [\"Why can't I (.*)\",\n",
    "    [   \"Do you think you should be able to %1?\",\n",
    "        \"If you could %1, what would you do?\",\n",
    "        \"I don't know -- why can't you %1?\",\n",
    "        \"Have you really tried?\"]],\n",
    "    [\"I can't (.*)\",\n",
    "    [   \"How do you know you can't %1?\",\n",
    "        \"Perhaps you could %1 if you tried.\",\n",
    "        \"What would it take for you to %1?\"]],\n",
    "    [\"I am (.*)\",\n",
    "    [   \"Did you come to me because you are %1?\",\n",
    "        \"How long have you been %1?\",\n",
    "        \"How do you feel about being %1?\"]],\n",
    "    [\"I'm (.*)\",\n",
    "    [   \"How does being %1 make you feel?\",\n",
    "        \"Do you enjoy being %1?\",\n",
    "        \"Why do you tell me you're %1?\",\n",
    "        \"Why do you think you're %1?\"]],\n",
    "    [\"Are you (.*)\",\n",
    "    [   \"Why does it matter whether I am %1?\",\n",
    "        \"Would you prefer it if I were not %1?\",\n",
    "        \"Perhaps you believe I am %1.\",\n",
    "        \"I may be %1 -- what do you think?\"]],\n",
    "    [\"What (.*)\",\n",
    "    [   \"Why do you ask?\",\n",
    "        \"How would an answer to that help you?\",\n",
    "        \"What do you think?\"]],\n",
    "    [\"How (.*)\",\n",
    "    [   \"How do you suppose?\",\n",
    "        \"Perhaps you can answer your own question.\",\n",
    "        \"What is it you're really asking?\"]],\n",
    "    [\"Because (.*)\",\n",
    "    [   \"Is that the real reason?\",\n",
    "        \"What other reasons come to mind?\",\n",
    "        \"Does that reason apply to anything else?\",\n",
    "        \"If %1, what else must be true?\"]],\n",
    "    [\"(.*) sorry (.*)\",\n",
    "    [   \"There are many times when no apology is needed.\",\n",
    "        \"What feelings do you have when you apologize?\"]],\n",
    "    [\"Hello(.*)\",\n",
    "    [   \"Hello... I'm glad you could drop by today.\",\n",
    "        \"Hi there... how are you today?\",\n",
    "        \"Hello, how are you feeling today?\"]],\n",
    "    [\"I think (.*)\",\n",
    "    [   \"Do you doubt %1?\",\n",
    "        \"Do you really think so?\",\n",
    "        \"But you're not sure %1?\"]],\n",
    "    [\"(.*) friend(.*)\",\n",
    "    [   \"Tell me more about your friends.\",\n",
    "        \"When you think of a friend, what comes to mind?\",\n",
    "        \"Why don't you tell me about a childhood friend?\"]],\n",
    "    [\"Yes\",\n",
    "    [   \"You seem quite sure.\",\n",
    "        \"OK, but can you elaborate a bit?\"]],\n",
    "    [\"No\",\n",
    "    [ \"Why not?\"]],\n",
    "    [\"(.*) computer(.*)\",\n",
    "    [   \"Are you really talking about me?\",\n",
    "        \"Does it seem strange to talk to a computer?\",\n",
    "        \"How do computers make you feel?\",\n",
    "        \"Do you feel threatened by computers?\"]],\n",
    "    [\"Is it (.*)\",\n",
    "    [   \"Do you think it is %1?\",\n",
    "        \"Perhaps it's %1 -- what do you think?\",\n",
    "        \"If it were %1, what would you do?\",\n",
    "        \"It could well be that %1.\"]],\n",
    "    [\"It is (.*)\",\n",
    "    [   \"You seem very certain.\",\n",
    "        \"If I told you that it probably isn't %1, what would you feel?\"]],\n",
    "    [\"Can you (.*)\",\n",
    "    [   \"What makes you think I can't %1?\",\n",
    "        \"If I could %1, then what?\",\n",
    "        \"Why do you ask if I can %1?\"]],\n",
    "    [\"Can I (.*)\",\n",
    "    [   \"Perhaps you don't want to %1.\",\n",
    "        \"Do you want to be able to %1?\",\n",
    "        \"If you could %1, would you?\"]],\n",
    "    [\"You are (.*)\",\n",
    "    [   \"Why do you think I am %1?\",\n",
    "        \"Does it please you to think that I'm %1?\",\n",
    "        \"Perhaps you would like me to be %1.\",\n",
    "        \"Perhaps you're really talking about yourself?\"]],\n",
    "    [\"You're (.*)\",\n",
    "    [   \"Why do you say I am %1?\",\n",
    "        \"Why do you think I am %1?\",\n",
    "        \"Are we talking about you, or me?\"]],\n",
    "    [\"I don't (.*)\",\n",
    "    [   \"Don't you really %1?\",\n",
    "        \"Why don't you %1?\",\n",
    "        \"Do you want to %1?\"]],\n",
    "    [\"I feel (.*)\",\n",
    "    [   \"Good, tell me more about these feelings.\",\n",
    "        \"Do you often feel %1?\",\n",
    "        \"When do you usually feel %1?\",\n",
    "        \"When you feel %1, what do you do?\"]],\n",
    "    [\"I have (.*)\",\n",
    "    [   \"Why do you tell me that you've %1?\",\n",
    "        \"Have you really %1?\",\n",
    "        \"Now that you have %1, what will you do next?\"]],\n",
    "    [\"I would (.*)\",\n",
    "    [   \"Could you explain why you would %1?\",\n",
    "        \"Why would you %1?\",\n",
    "        \"Who else knows that you would %1?\"]],\n",
    "    [\"Is there (.*)\",\n",
    "    [   \"Do you think there is %1?\",\n",
    "        \"It's likely that there is %1.\",\n",
    "        \"Would you like there to be %1?\"]],\n",
    "    [\"My (.*)\",\n",
    "    [   \"I see, your %1.\",\n",
    "        \"Why do you say that your %1?\",\n",
    "        \"When your %1, how do you feel?\"]],\n",
    "    [\"You (.*)\",\n",
    "    [   \"We should be discussing you, not me.\",\n",
    "        \"Why do you say that about me?\",\n",
    "        \"Why do you care whether I %1?\"]],\n",
    "    [\"Why (.*)\",\n",
    "    [   \"Why don't you tell me the reason why %1?\",\n",
    "        \"Why do you think %1?\" ]],\n",
    "    [\"I want (.*)\",\n",
    "    [   \"What would it mean to you if you got %1?\",\n",
    "        \"Why do you want %1?\",\n",
    "        \"What would you do if you got %1?\",\n",
    "        \"If you got %1, then what would you do?\"]],\n",
    "    [\"(.*) mother(.*)\",\n",
    "    [   \"Tell me more about your mother.\",\n",
    "        \"What was your relationship with your mother like?\",\n",
    "        \"How do you feel about your mother?\",\n",
    "        \"How does this relate to your feelings today?\",\n",
    "        \"Good family relations are important.\"]],\n",
    "    [\"(.*) father(.*)\",\n",
    "    [   \"Tell me more about your father.\",\n",
    "        \"How did your father make you feel?\",\n",
    "        \"How do you feel about your father?\",\n",
    "        \"Does your relationship with your father relate to your feelings today?\",\n",
    "        \"Do you have trouble showing affection with your family?\"]],\n",
    "    [\"(.*) child(.*)\",\n",
    "    [   \"Did you have close friends as a child?\",\n",
    "        \"What is your favorite childhood memory?\",\n",
    "        \"Do you remember any dreams or nightmares from childhood?\",\n",
    "        \"Did the other children sometimes tease you?\",\n",
    "        \"How do you think your childhood experiences relate to your feelings today?\"]],\n",
    "    [\"(.*)\\?\",\n",
    "    [   \"Why do you ask that?\",\n",
    "        \"Please consider whether you can answer your own question.\",\n",
    "        \"Perhaps the answer lies within yourself?\",\n",
    "        \"Why don't you tell me?\"]],\n",
    "    [\"quit\",\n",
    "    [   \"Thank you for talking with me.\",\n",
    "        \"Good-bye.\",\n",
    "        \"Thank you, that will be $150.  Have a good day!\"]],\n",
    "  [\"(.*)\",\n",
    "  [   \"Please tell me more.\",\n",
    "      \"Let's change focus a bit... Tell me about your family.\",\n",
    "      \"Can you elaborate on that?\",\n",
    "      \"Why do you say that %1?\",\n",
    "      \"I see.\",\n",
    "      \"Very interesting.\",\n",
    "      \"So %1.\",\n",
    "      \"I see.  And what does that tell you?\",\n",
    "      \"How does that make you feel?\",\n",
    "      \"How do you feel when you say that?\"]]\n",
    "]]\n",
    "\n",
    "def respond(sentence):\n",
    "    # find a match among keys, last one is quaranteed to match.\n",
    "    for rule, value in rules:\n",
    "        match = rule.search(sentence)\n",
    "        if match is not None:\n",
    "            # found a match ... stuff with corresponding value\n",
    "            # chosen randomly from among the available options\n",
    "            resp = random.choice(value)\n",
    "            # we've got a response... stuff in reflected text where indicated\n",
    "            while '%' in resp:\n",
    "                pos = resp.find('%')\n",
    "                num = int(resp[pos+1:pos+2])\n",
    "                resp = resp.replace(resp[pos:pos+2], translate(match.group(num)))\n",
    "            return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 shell에서 작동하는 interactive version을 만들고자 한다면, 아래 코드를 추가하면 된다.\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    print(\"\"\"\n",
    "    Therapist\n",
    "    ---------\n",
    "    Talk to the program by typing in plain English, using normal upper-\n",
    "    and lower-case letters and punctuation.  Enter \"quit\" when done.'\"\"\")\n",
    "    print('='*72)\n",
    "    print(\"Hello.  How are you feeling today?\")\n",
    "    s = \"\"\n",
    "    while s != \"quit\":\n",
    "        s = input(\">\")\n",
    "        while s and s[-1] in \"!.\":\n",
    "            s = s[:-1]\n",
    "        print(respond(s))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 새로운 translation 방법을 적용하여 개선된 Eliza의 response이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I see, your mother hates you.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"My mother hates me.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So you will do anything I ask.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previous version response: 'you will do anything me ask'\n",
    "respond('I will do anything you ask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"you are ``possibly,'' maybe crazy\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"I'm ``possibly,'' maybe crazy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the dogs were crazy'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond('the dogs were crazy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the dog was crazy'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previous version response: 'the dog were crazy'\n",
    "respond('the dog was crazy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do you say that your dog was crazy?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previous version response: 'Why do you say that your dog were crazy?'\n",
    "respond(\"My dog was crazy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do you say that you were crazy?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"I was crazy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do you care whether I said Fred was crazy?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previous version response: 'Why do you care whether I said fred were crazy?'\n",
    "respond(\"You said Fred was crazy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So you asked me.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond(\"I asked you.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
